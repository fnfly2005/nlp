{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语法困境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.grammar import CFG\n",
    "#从文本生成上下文无关语法 \n",
    "groucho_grammar = CFG.fromstring('''\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "''')\n",
    "\n",
    "sent = ['I','shot','an','elephant','in','my','pajamas']\n",
    "parser = nltk.parse.chart.ChartParser(groucho_grammar)#通用图表分析器\n",
    "trees = parser.parse(sent)#为语句生成分析树的迭代器\n",
    "for tree in trees:\n",
    "    print (tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文法的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上下文无关文法-简单文法\n",
    "context-free grammar，CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> 'saw' | 'ate' | 'walked'\n",
    "NP -> 'John' | 'Mary' | 'Bob' | Det N | Det N PP\n",
    "Det -> 'a' | 'an' | 'the' | 'my'\n",
    "N -> 'man' | 'dog' | 'cat' | 'telescope' | 'park'\n",
    "P -> 'in' | 'on' | 'by' | 'with'\n",
    "\"\"\")\n",
    "sent = ['Mary','saw','Bob']\n",
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)#, trace=2\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print (tree)\n",
    "    tree.draw()\n",
    "\n",
    "sent2 = [x.lower() for x in \"The dog saw a man in the park\".split()]\n",
    "for tree in rd_parser.parse(sent2):\n",
    "    print (tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print (tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归下降分析\n",
    "递归下降分析器在上述过程中建立分析树。带着最初的目标(找到一个 S)，创建 S 根 节点。随着上述过程使用文法的产生式递归扩展，分析树不断向下延伸(故名为递归下降)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)\n",
    "sent ='Mary saw a dog'.split()\n",
    "for t in rd_parser.parse(sent):\n",
    "    print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移进-归约分析\n",
    "一种简单的自下而上分析器是移进-归约分析器。与所有自下而上的分析器一样，移进-归约分析器尝试找到对应文法生产式右侧的词和短语的序列，用左侧的替换它们，直到整个句子归约为一个 S\n",
    "\n",
    "移进-规约分析器相比递归下降分析器的好处是，它们只建立与输入中的词对应的结构。 此外，每个结构它们只建立一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "nltk.app.srparser_app.app()#用于探索移进-归约解析器的图形工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parse = nltk.ShiftReduceParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for t in sr_parse.parse(sent):\n",
    "    print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 符合语句规则的子串表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1   2   3   4   5   6   7   \n",
      "0    NP  .   .   .   .   .   .   \n",
      "1    .   V   .   .   .   .   .   \n",
      "2    .   .   Det .   .   .   .   \n",
      "3    .   .   .   N   .   .   .   \n",
      "4    .   .   .   .   P   .   .   \n",
      "5    .   .   .   .   .   Det .   \n",
      "6    .   .   .   .   .   .   N   \n",
      "\n",
      "WFST 1   2   3   4   5   6   7   \n",
      "0    NP  .   .   S   .   .   S   \n",
      "1    .   V   .   VP  .   .   VP  \n",
      "2    .   .   Det NP  .   .   .   \n",
      "3    .   .   .   N   .   .   .   \n",
      "4    .   .   .   .   P   .   PP  \n",
      "5    .   .   .   .   .   Det NP  \n",
      "6    .   .   .   .   .   .   N   \n",
      "[2] Det [3]   N [4] ==> [2]  NP [4]\n",
      "[5] Det [6]   N [7] ==> [5]  NP [7]\n",
      "[1]   V [2]  NP [4] ==> [1]  VP [4]\n",
      "[4]   P [5]  NP [7] ==> [4]  PP [7]\n",
      "[0]  NP [1]  VP [4] ==> [0]   S [4]\n",
      "[1]  VP [4]  PP [7] ==> [1]  VP [7]\n",
      "[0]  NP [1]  VP [7] ==> [0]   S [7]\n"
     ]
    }
   ],
   "source": [
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])#返回语法结果:词性->词 rhs仅返回右边具有给定第一项的项目\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst,tokens,grammar,trace=False):\n",
    "    index=dict((p.rhs(),p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2,numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end=start +span\n",
    "            for mid in range(start+1,end):\n",
    "                nt1,nt2 = wfst[start][mid],wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1,nt2) in index:\n",
    "                    wfst[start][end]= index[(nt1,nt2)]\n",
    "                    if trace:\n",
    "                        print (\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % (start,nt1,mid,nt2,end,start,index[(nt1,nt2)],end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst,tokens):\n",
    "    print ('\\nWFST ' + ''.join([(\"%-4d\" % i) for i in range(1, len(wfst))]))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print (\"%d\" % i,end=\"    \")\n",
    "        for j in range(1,len(wfst)):\n",
    "            print (\"%-4s\" % (wfst[i][j] or '.'),end=\"\")\n",
    "        print (\"\")\n",
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)\n",
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)\n",
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
