{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语法困境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.grammar import CFG\n",
    "#从文本生成上下文无关语法 \n",
    "groucho_grammar = CFG.fromstring('''\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "''')\n",
    "\n",
    "sent = ['I','shot','an','elephant','in','my','pajamas']\n",
    "parser = nltk.parse.chart.ChartParser(groucho_grammar)#通用图表分析器\n",
    "trees = parser.parse(sent)#为语句生成分析树的迭代器\n",
    "for tree in trees:\n",
    "    print (tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文法的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上下文无关文法-简单文法\n",
    "context-free grammar，CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> 'saw' | 'ate' | 'walked'\n",
    "NP -> 'John' | 'Mary' | 'Bob' | Det N | Det N PP\n",
    "Det -> 'a' | 'an' | 'the' | 'my'\n",
    "N -> 'man' | 'dog' | 'cat' | 'telescope' | 'park'\n",
    "P -> 'in' | 'on' | 'by' | 'with'\n",
    "\"\"\")\n",
    "sent = ['Mary','saw','Bob']\n",
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)#, trace=2\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print (tree)\n",
    "    tree.draw()\n",
    "\n",
    "sent2 = [x.lower() for x in \"The dog saw a man in the park\".split()]\n",
    "for tree in rd_parser.parse(sent2):\n",
    "    print (tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print (tree)\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归下降分析\n",
    "递归下降分析器在上述过程中建立分析树。带着最初的目标(找到一个 S)，创建 S 根 节点。随着上述过程使用文法的产生式递归扩展，分析树不断向下延伸(故名为递归下降)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.parse.recursivedescent.RecursiveDescentParser(grammar1)\n",
    "sent ='Mary saw a dog'.split()\n",
    "for t in rd_parser.parse(sent):\n",
    "    print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 移进-归约分析\n",
    "一种简单的自下而上分析器是移进-归约分析器。与所有自下而上的分析器一样，移进-归约分析器尝试找到对应文法生产式右侧的词和短语的序列，用左侧的替换它们，直到整个句子归约为一个 S\n",
    "\n",
    "移进-规约分析器相比递归下降分析器的好处是，它们只建立与输入中的词对应的结构。 此外，每个结构它们只建立一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: VP -> V NP PP will never be used\n"
     ]
    }
   ],
   "source": [
    "nltk.app.srparser_app.app()#用于探索移进-归约解析器的图形工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parse = nltk.ShiftReduceParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for t in sr_parse.parse(sent):\n",
    "    print (t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 符合语句规则的子串表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST 1   2   3   4   5   6   7   \n",
      "0    NP  .   .   .   .   .   .   \n",
      "1    .   V   .   .   .   .   .   \n",
      "2    .   .   Det .   .   .   .   \n",
      "3    .   .   .   N   .   .   .   \n",
      "4    .   .   .   .   P   .   .   \n",
      "5    .   .   .   .   .   Det .   \n",
      "6    .   .   .   .   .   .   N   \n",
      "\n",
      "WFST 1   2   3   4   5   6   7   \n",
      "0    NP  .   .   S   .   .   S   \n",
      "1    .   V   .   VP  .   .   VP  \n",
      "2    .   .   Det NP  .   .   .   \n",
      "3    .   .   .   N   .   .   .   \n",
      "4    .   .   .   .   P   .   PP  \n",
      "5    .   .   .   .   .   Det NP  \n",
      "6    .   .   .   .   .   .   N   \n",
      "[2] Det [3]   N [4] ==> [2]  NP [4]\n",
      "[5] Det [6]   N [7] ==> [5]  NP [7]\n",
      "[1]   V [2]  NP [4] ==> [1]  VP [4]\n",
      "[4]   P [5]  NP [7] ==> [4]  PP [7]\n",
      "[0]  NP [1]  VP [4] ==> [0]   S [4]\n",
      "[1]  VP [4]  PP [7] ==> [1]  VP [7]\n",
      "[0]  NP [1]  VP [7] ==> [0]   S [7]\n"
     ]
    }
   ],
   "source": [
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens+1)] for j in range(numtokens+1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs=tokens[i])#返回语法结果:词性->词 rhs仅返回右边具有给定第一项的项目\n",
    "        wfst[i][i+1] = productions[0].lhs()\n",
    "    return wfst\n",
    "\n",
    "def complete_wfst(wfst,tokens,grammar,trace=False):\n",
    "    index=dict((p.rhs(),p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2,numtokens+1):\n",
    "        for start in range(numtokens+1-span):\n",
    "            end=start +span\n",
    "            for mid in range(start+1,end):\n",
    "                nt1,nt2 = wfst[start][mid],wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1,nt2) in index:\n",
    "                    wfst[start][end]= index[(nt1,nt2)]\n",
    "                    if trace:\n",
    "                        print (\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % (start,nt1,mid,nt2,end,start,index[(nt1,nt2)],end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst,tokens):\n",
    "    print ('\\nWFST ' + ''.join([(\"%-4d\" % i) for i in range(1, len(wfst))]))\n",
    "    for i in range(len(wfst)-1):\n",
    "        print (\"%d\" % i,end=\"    \")\n",
    "        for j in range(1,len(wfst)):\n",
    "            print (\"%-4s\" % (wfst[i][j] or '.'),end=\"\")\n",
    "        print (\"\")\n",
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)\n",
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)\n",
    "wfst1 = complete_wfst(wfst0, tokens, groucho_grammar, trace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 依存关系和依存文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import DependencyGrammar #依赖语法。DependencyGrammar由一组语法组成。每个语法都指定一对词之间的标题/修饰词关系。\n",
    "from nltk.parse import (\n",
    "     DependencyGraph,\n",
    "     ProjectiveDependencyParser,\n",
    "     NonprojectiveDependencyParser)\n",
    "groucho_dep_grammar=DependencyGrammar.fromstring(\"\"\"\n",
    "'shot' -> 'I' | 'elephant' | 'in'\n",
    "'elephant' -> 'an' | 'in'\n",
    "'in' -> 'pajamas'\n",
    "'pajamas' -> 'my'\n",
    "\"\"\")\n",
    "print (groucho_dep_grammar)\n",
    "pdp = ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)\n",
    "for tree in trees:\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 树库和文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n",
      "(VP\n",
      "  (VBN named)\n",
      "  (S\n",
      "    (NP-SBJ (-NONE- *-1))\n",
      "    (NP-PRD\n",
      "      (NP (DT a) (JJ nonexecutive) (NN director))\n",
      "      (PP\n",
      "        (IN of)\n",
      "        (NP (DT this) (JJ British) (JJ industrial) (NN conglomerate))))))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]#获取已解析的句子结构\n",
    "print (t)\n",
    "def filter(tree):\n",
    "    child_nodes=[child.label() for child in tree\n",
    "                if isinstance(child,nltk.Tree)]\n",
    "    return (tree.label()=='VP') and ('S' in child_nodes)\n",
    "print ([subtree for tree in treebank.parsed_sents()\n",
    " for subtree in tree.subtrees(filter)][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%-below-level N: ['left'] V: ['be']\n",
      "%-from-year N: ['was'] V: ['declined', 'dropped', 'fell', 'grew', 'increased', 'plunged', 'rose', 'was']\n",
      "%-in-August N: ['was'] V: ['climbed', 'fell', 'leaping', 'rising', 'rose']\n",
      "%-in-September N: ['increased'] V: ['climbed', 'declined', 'dropped', 'edged', 'fell', 'grew', 'plunged', 'rose', 'slipped']\n"
     ]
    }
   ],
   "source": [
    "entries = nltk.corpus.ppattach.attachments('training')\n",
    "table = nltk.defaultdict(lambda: nltk.defaultdict(set))\n",
    "for entry in entries:\n",
    "    key = entry.noun1 + '-' + entry.prep + '-' + entry.noun2\n",
    "    table[key][entry.attachment].add(entry.verb)\n",
    "    \n",
    "n=0\n",
    "for key in sorted(table):\n",
    "    if len(table[key]) > 1:\n",
    "        print (key, 'N:', sorted(table[key]['N']), 'V:', sorted(table[key]['V']))\n",
    "    n+=1\n",
    "    if n == 100:\n",
    "        break\n",
    "\n",
    "nltk.corpus.sinica_treebank.parsed_sents()[3450].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有害的歧义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP fish) (V fish) (NP (NP fish) (Sbar (NP fish) (V fish))))\n",
      "(S (NP (NP fish) (Sbar (NP fish) (V fish))) (V fish) (NP fish))\n"
     ]
    }
   ],
   "source": [
    "grammar=CFG.fromstring(\"\"\"\n",
    "S -> NP V NP\n",
    "NP -> NP Sbar\n",
    "Sbar -> NP V\n",
    "NP -> 'fish'\n",
    "V -> 'fish'\n",
    "\"\"\")\n",
    "tokens = [\"fish\"]*5\n",
    "cp = nltk.ChartParser(grammar)\n",
    "for tree in cp.parse(tokens):\n",
    "    print (tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加权文法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gave NP: the chefs / NP: a standing ovation\n",
      "give NP: advertisers / NP: discounts for maintaining or increasing ad sp...\n",
      "give NP: it / PP-DTV: to the politicians\n",
      "gave NP: them / NP: similar help\n",
      "give NP: them / NP: \n",
      "give NP: only French history questions / PP-DTV: to students in a Europe...\n",
      "give NP: federal judges / NP: a raise\n",
      "give NP: consumers / NP: the straight scoop on the U.S. waste crisis\n",
      "gave NP: Mitsui / NP: access to a high-tech medical product\n",
      "give NP: Mitsubishi / NP: a window on the U.S. glass industry\n",
      "give NP: much thought / PP-DTV: to the rates she was receiving , nor to ...\n",
      "give NP: your Foster Savings Institution / NP: the gift of hope and free...\n",
      "give NP: market operators / NP: the authority to suspend trading in futu...\n",
      "gave NP: quick approval / PP-DTV: to $ 3.18 billion in supplemental appr...\n",
      "give NP: the Transportation Department / NP: up to 50 days to review any...\n",
      "give NP: the president / NP: such power\n",
      "give NP: me / NP: the heebie-jeebies\n",
      "give NP: holders / NP: the right , but not the obligation , to buy a cal...\n",
      "gave NP: Mr. Thomas / NP: only a `` qualified '' rating , rather than ``...\n",
      "give NP: the president / NP: line-item veto power\n"
     ]
    }
   ],
   "source": [
    "def give(t):\n",
    "    return t.label() == 'VP' and len(t)>2 and t[1].label() == 'NP' \\\n",
    "        and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP') \\\n",
    "        and ('give' in t[0].leaves() or 'gave' in t[0].leaves())\n",
    "\n",
    "def sent(t):\n",
    "    return ' '.join(token for token in t.leaves() if token[0] not in '*-0')\n",
    "\n",
    "def print_node(t,width):\n",
    "    output = \"%s %s: %s / %s: %s\" %\\\n",
    "        (sent(t[0]),t[1].label(),sent(t[1]),t[2].label(),sent(t[2]))\n",
    "    if len(output) > width:\n",
    "        output = output[:width] + \"...\"\n",
    "    print (output)\n",
    "    \n",
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    for t in tree.subtrees(give):\n",
    "        print_node(t,72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 9 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> TV NP [0.4]\n",
      "    VP -> IV [0.3]\n",
      "    VP -> DatV NP NP [0.3]\n",
      "    TV -> 'saw' [1.0]\n",
      "    IV -> 'ate' [1.0]\n",
      "    DatV -> 'gave' [1.0]\n",
      "    NP -> 'telescopes' [0.8]\n",
      "    NP -> 'Jack' [0.2]\n",
      "(S (NP Jack) (VP (TV saw) (NP telescopes))) (p=0.064)\n"
     ]
    }
   ],
   "source": [
    "from nltk.grammar import PCFG\n",
    "grammar = PCFG.fromstring(\"\"\"\n",
    "S -> NP VP [1.0]\n",
    "VP -> TV NP [0.4]\n",
    "VP -> IV [0.3]\n",
    "VP -> DatV NP NP [0.3]\n",
    "TV -> 'saw' [1.0]\n",
    "IV -> 'ate' [1.0]\n",
    "DatV -> 'gave' [1.0]\n",
    "NP -> 'telescopes' [0.8]\n",
    "NP -> 'Jack' [0.2]\n",
    "\"\"\")\n",
    "print (grammar)\n",
    "viterbi_parser = nltk.parse.viterbi.ViterbiParser(grammar)#一个自下而上的pcfg解析器\n",
    "for vp in viterbi_parser.parse(['Jack','saw','telescopes']):\n",
    "    print (vp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
