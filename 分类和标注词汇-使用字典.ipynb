{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python-常用对象API-字典dict类-创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'}\n",
      "['colorless', 'ideas', 'sleep', 'furiously']\n"
     ]
    }
   ],
   "source": [
    "pos = dict(colorless='ADJ', ideas='N', sleep='V', furiously='ADV')\n",
    "print (pos)\n",
    "print (list(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默认字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "N\n",
      "dict_items([('sleep', ['N', 'V']), ('blog', 'N')])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "frequency = nltk.defaultdict(int)\n",
    "frequency['colorless'] = 4\n",
    "print(frequency['ideas'])\n",
    "\n",
    "pos = nltk.defaultdict(lambda: 'N')\n",
    "pos['sleep'] = ['N', 'V']\n",
    "print (pos['blog'])\n",
    "print(pos.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要创建一个默认字典，映射每个词为它们的替换词。最频繁的 n 个词将被映射到 它们自己。其他的被映射到 UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UNK', 'Alice', \"'\", 's', 'UNK', 'in', 'UNK', 'by', 'UNK', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "alice = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "vocab = nltk.FreqDist(alice)\n",
    "v1000 = sorted(vocab.items(),key=itemgetter(1),reverse=True)[:500]\n",
    "mapping = nltk.defaultdict(lambda: 'UNK')\n",
    "for item in v1000:\n",
    "    mapping[item[0]]=item[0]\n",
    "\n",
    "alice2 = [mapping[v] for v in alice]\n",
    "print(alice2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更新字典\n",
    "\n",
    "默认字典的习惯用法\n",
    "\n",
    " nltk.Index 是一个额外支持初始化的 defaultdict(list)。类似的，nltk. FreqDist 本质上是一个额外支持初始化的 defaultdict(int)(附带排序和 绘图方法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'ADJ', 'VERB', 'ADP']\n",
      "['NOUN', 'VERB', 'ADP', '.', 'DET']\n",
      "['abactinally', 'abandonedly', 'abasedly', 'abashedly', 'abashlessly']\n",
      "['blazy', 'bleezy', 'blowzy', 'boozy', 'breezy']\n",
      "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']\n",
      "['entrail', 'latrine', 'ratline', 'reliant', 'retinal', 'trenail']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "#习惯用法一\n",
    "counts = nltk.defaultdict(int)\n",
    "for (word, tag) in brown.tagged_words(categories='news',tagset='universal'):\n",
    "    counts[tag] += 1   \n",
    "print(list(counts)[:5])\n",
    "\n",
    "#对字典进行排序并提取其键列表\n",
    "print([t for t, c in sorted(counts.items(), key=itemgetter(1), reverse=True)][:5])\n",
    "\n",
    "#习惯用法二\n",
    "#实例一\n",
    "last_letters = nltk.defaultdict(list)\n",
    "words = nltk.corpus.words.words('en')\n",
    "for word in words:\n",
    "    key = word[-2:]\n",
    "    last_letters[key].append(word)\n",
    "print(last_letters['ly'][:5])\n",
    "print(last_letters['zy'][:5])\n",
    "\n",
    "#实例二\n",
    "anagrams = nltk.defaultdict(list)\n",
    "for word in words:\n",
    "    key = ''.join(sorted(word))#拆开词的字符重新排序组合\n",
    "    anagrams[key].append(word)#将这些重组后一样顺序的词追加到一个链表里\n",
    "print(anagrams['aeilnrt'])\n",
    "\n",
    "#等同以上用法\n",
    "anagrams = nltk.Index((''.join(sorted(w)), w) for w in words)\n",
    "print(anagrams['aeilnrt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 复杂键和值\n",
    "\n",
    "这个例子使用一个字典，它的条目的默认值也是一个字典(其默认值是 int()，即 0)。\n",
    "请注意我们如何遍历已标注语料库的双连词，每次遍历处理一个词-标记对。每次通过循 环时，我们更新字典 pos 中的条目 (t1, w2)，一个标记和它后面的词。当我们在 pos 中查找一个项目时，我们必须指定一个复合键，然后得到一个字典对象。一个 POS 标注 器可以使用这些信息来决定词 right，前面是一个限定词时，应标注为 ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET Fulton NOUN\n",
      "defaultdict(<function <lambda> at 0x1a244266a8>, {('DET', 'Fulton'): defaultdict(<class 'int'>, {'NOUN': 1})})\n",
      "Fulton NOUN County NOUN\n",
      "defaultdict(<function <lambda> at 0x1a244266a8>, {('DET', 'Fulton'): defaultdict(<class 'int'>, {'NOUN': 1}), ('NOUN', 'County'): defaultdict(<class 'int'>, {'NOUN': 1})})\n"
     ]
    }
   ],
   "source": [
    "pos = nltk.defaultdict(lambda: nltk.defaultdict(int))\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "n = 0\n",
    "for ((w1, t1), (w2, t2)) in nltk.bigrams(brown_news_tagged):\n",
    "    n=n+1\n",
    "    print (w1,t1,w2,t2)\n",
    "    pos[(t1, w2)][t2] += 1\n",
    "    print (pos)\n",
    "    if n == 2:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
