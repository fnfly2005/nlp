{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "wordlist = [ w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "searchlist = [w for w in wordlist if re.search('^ab.+ed$',w)]#re.search() 查找并返回布尔值\n",
    "searchlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "· 通配符，匹配所有字符\n",
    "^abc 匹配以 abc 开始的字符串\n",
    "abc$ 匹配以 abc 结尾的字符串\n",
    "[abc] 匹配字符集合中的一个\n",
    "[A-Z0-9] 匹配字符一个范围\n",
    "ed|ing|s 匹配指定的一个字符串(析取)\n",
    "* 前面的项目零个或多个，如 a*, [a-z]* (也叫 Kleene 闭包) + 前面的项目 1 个或多个，如 a+, [a-z]+\n",
    "? 前面的项目零个或 1 个(即:可选)如:a?, [a-z]?\n",
    "{n} 重复 n 次，n 为非负整数\n",
    "{n,} 至少重复 n 次\n",
    "{,n} 重复不多于 n 次\n",
    "{m,n} 至少重复 m 次不多于 n 次\n",
    "a(b|c)+ 括号表示操作符的范围"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u', 'e', 'a', 'i', 'a']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)[:5]#返回一个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('ea', 476), ('oi', 65), ('ou', 329), ('io', 549), ('ee', 217), ('ie', 331), ('ui', 95), ('ua', 109), ('ai', 261), ('ue', 105), ('ia', 253), ('ei', 86), ('iai', 1), ('oo', 174), ('au', 106), ('eau', 10), ('oa', 59), ('oei', 1), ('oe', 15), ('eo', 39), ('uu', 1), ('eu', 18), ('iu', 14), ('aii', 1), ('aiia', 1), ('ae', 11), ('aa', 3), ('oui', 6), ('ieu', 3), ('ao', 6), ('iou', 27), ('uee', 4), ('eou', 5), ('aia', 1), ('uie', 3), ('iao', 1), ('eei', 2), ('uo', 8), ('uou', 5), ('eea', 1), ('ueui', 1), ('ioa', 1), ('ooi', 1)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                   for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "fd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\\nof the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\\nof frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\\nrghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\\nand the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "tokenlist=[compress(w) for w in english_udhr[:75]]\n",
    "nltk.tokenwrap(tokenlist) # 打印文本标记列表，在空白处断行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kasuari']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "                 for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)#利用元组数列生成字典\n",
    "cv_index['su']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查找词干"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ing']\n",
      "['processing']\n",
      "[('process', 'ing')]\n",
      "[('language', '')]\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ing','ly','ed','ious','ies','ive','es','s','ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word\n",
    "print (re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$','processing'))#等同以上函数\n",
    "print (re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$','processing'))\n",
    "print (re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$','processing'))\n",
    "print (re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$','language'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS', ':', 'Listen', ',', 'strange']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem,suffix = re.findall(regexp,word)[0]\n",
    "    return word\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government. Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "[stem(t) for t in tokens][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搜索已分词文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的例子中，我们使用<.*>，它将匹配所有单个标识符，将它括在括号里，于是只 匹配词(例如:monied)而不匹配短语(例如:a monied man)\n",
    "第二个例子找出以词“br o”结尾的三个词组成的短语\n",
    "第三个例子找出以字母“l”开始的三个或更多词组成的 序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a monied man; a nervous man; a dangerous man; a white man; a white\n",
      "man; a white man; a pious man; a queer man; a good man; a mature man;\n",
      "a white man; a Cape man; a great man; a wise man; a wise man; a\n",
      "butterless man; a white man; a fiendish man; a pale man; a furious\n",
      "man; a better man; a certain man; a complete man; a dismasted man; a\n",
      "younger man; a brave man; a brave man; a brave man; a brave man\n",
      "None\n",
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "print (moby.findall(r\"<a> <.*> <man>\"))\n",
    "print (moby.findall(r\"<a> (<.*>) <man>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat = nltk.Text(nps_chat.words())\n",
    "chat.findall(r\"<.*> <.*> <bro>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
